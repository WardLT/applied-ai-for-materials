{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input Data\n",
    "The first step of building a model with TensorFlow is to get the data in an easy-to-use format.\n",
    "For TensorFlow, easy-to-use means that the data is stored in matrix formats and in a format that can be rapidly read from disk.\n",
    "Here, we show how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from typing import List, Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from mpnn.data import make_tfrecord\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "It is stored on a [GitHub page](https://github.com/globus-labs/g4mp2-atomization-energy) from a previous project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25000 training entries\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('../datasets/qm9.json.gz', lines=True)\n",
    "print(f'Loaded {len(data)} training entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the SMILES to RDKit molecules. \n",
    "\n",
    "Make sure to add the Hydrogens in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 104 ms, total: 1.76 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['mol'] = data['smiles_0'].apply(Chem.MolFromSmiles).apply(Chem.AddHs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Molecule Records to Dictionaries of Arrays\n",
    "While RDKit molecules are convenient, TensorFlow works with numeric _tensors_. The next few cells show how to convert an RDKit molecule to a format.\n",
    "\n",
    "Our first step is to prepare to convert types of atoms and bonds to numeric values. We do that by finding all types of atoms and Take a look at [./mpnn/data.py](./mpnn/data.py) to get a better idea of what this function does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_type_lookup_tables(mols: List[Chem.Mol]) -> Tuple[List[int], List[str]]:\n",
    "    \"\"\"Create lists of observed atom and bond types\n",
    "\n",
    "    Args:\n",
    "        mols: List of molecules used for our training set\n",
    "    Returns:\n",
    "        - List of atom types (elements)\n",
    "        - List of bond types (elements)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the lists\n",
    "    atom_types = set()\n",
    "    bond_types = set()\n",
    "\n",
    "    # Get all types observed in these graphs\n",
    "    for mol in mols:\n",
    "        atom_types.update([x.GetAtomicNum() for x in mol.GetAtoms()])\n",
    "        bond_types.update([x.GetBondType() for x in mol.GetBonds()])\n",
    "\n",
    "    # Return as sorted lists\n",
    "    return sorted(atom_types), sorted(bond_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 types of atoms: [1, 6, 7, 8, 9]\n",
      "Found 4 types of bonds: [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE, rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]\n"
     ]
    }
   ],
   "source": [
    "atom_types, bond_types = make_type_lookup_tables(data['mol'])\n",
    "print(f'Found {len(atom_types)} types of atoms: {atom_types}')\n",
    "print(f'Found {len(bond_types)} types of bonds: {bond_types}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to convert the molecules into dictionaries. We need to store the type of each atom in a molecule, the types of bonds, and which bonds connect which other atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mol_to_dict(mol: Chem.Mol, atom_types: List[int], bond_types: List[str]) -> dict:\n",
    "    \"\"\"Convert RDKit representation of a molecule to an MPNN-ready dict\n",
    "    \n",
    "    Args:\n",
    "        mol: Molecule to be converted\n",
    "        atom_types: Lookup table of observed atom types\n",
    "        bond_types: Lookup table of observed bond types\n",
    "    Returns:\n",
    "        (dict) Molecule as a dict\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the atom types, look them up in the atom_type list\n",
    "    atom_type = [a.GetAtomicNum() for a in mol.GetAtoms()]\n",
    "    atom_type_id = list(map(atom_types.index, atom_type))\n",
    "\n",
    "    # Get the bond types and which atoms these connect\n",
    "    connectivity = []\n",
    "    edge_type = []\n",
    "    for bond in mol.GetBonds():\n",
    "        # Get information about the bond\n",
    "        a = bond.GetBeginAtomIdx()\n",
    "        b = bond.GetEndAtomIdx()\n",
    "        b_type = bond.GetBondType()\n",
    "        \n",
    "        # Store how they are connected\n",
    "        connectivity.append([a, b])\n",
    "        connectivity.append([b, a])\n",
    "        edge_type.append(b_type)\n",
    "        edge_type.append(b_type)\n",
    "    edge_type_id = list(map(bond_types.index, edge_type))\n",
    "\n",
    "    # Sort connectivity array by the first column\n",
    "    #  This is needed for the MPNN code to efficiently group messages for\n",
    "    #  each atom when performing the message passing step\n",
    "    connectivity = np.array(connectivity)\n",
    "    if connectivity.size > 0:\n",
    "        # Skip a special case of a molecule w/o bonds\n",
    "        inds = np.lexsort((connectivity[:, 1], connectivity[:, 0]))\n",
    "        connectivity = connectivity[inds, :]\n",
    "\n",
    "        # Tensorflow's \"segment_sum\" will cause problems if the last atom\n",
    "        #  is not bonded because it returns an array\n",
    "        if connectivity.max() != len(atom_type) - 1:\n",
    "            smiles = convert_nx_to_smiles(graph)\n",
    "            raise ValueError(f\"Problem with unconnected atoms for {smiles}\")\n",
    "    else:\n",
    "        connectivity = np.zeros((0, 2))\n",
    "\n",
    "    return {\n",
    "        'n_atom': len(atom_type),\n",
    "        'n_bond': len(edge_type),\n",
    "        'atom': atom_type_id,\n",
    "        'bond': edge_type_id,\n",
    "        'connectivity': connectivity\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show Methane and as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_atom': 5,\n",
       " 'n_bond': 8,\n",
       " 'atom': [1, 0, 0, 0, 0],\n",
       " 'bond': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'connectivity': array([[0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [1, 0],\n",
       "        [2, 0],\n",
       "        [3, 0],\n",
       "        [4, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_mol_to_dict(Chem.AddHs(Chem.MolFromSmiles('C')), atom_types, bond_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking this off:\n",
    "- Methane has 5 atoms\n",
    "- There are 4 bonds (8 when you count both forward and backward)\n",
    "- The first atom is a Carbon (type 1 in our lookup table)\n",
    "- The remaining atoms are Hydrogen (type 0 in our lookup table)\n",
    "- All bonds are single bonds (type 0 in our lookup table)\n",
    "- All bonds either start or end in the carbon atom (atom number 0)\n",
    "\n",
    "It looks like it is working correctly, so let's run on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dict'] = data['mol'].apply(lambda x: convert_mol_to_dict(x, atom_types, bond_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Data as TFRecords\n",
    "Tensorflow has a preferred data format, [`TFRecord`](https://www.tensorflow.org/tutorials/load_data/tfrecord), which stores data in a binary format that is fast to read from disk. The details of it are a little more advanced for this tutorial but the short version is that we must convert data to this binary format then save it into a special archive format.\n",
    "\n",
    "The `make_tfrecord` function takes one of these dicionaries and stores it in binary format. You make notice some familiar words in this binary format, such as `n_bond`, but most of it is in a format that is not for humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\xf4\\x01\\np\\n\\x0cconnectivity\\x12`\\x1a^\\n\\\\\\x00\\x01\\x00\\t\\x00\\n\\x00\\x0b\\x01\\x00\\x01\\x02\\x01\\x05\\x02\\x01\\x02\\x03\\x02\\x06\\x03\\x02\\x03\\x04\\x03\\x0c\\x03\\r\\x04\\x03\\x04\\x05\\x04\\x0e\\x04\\x0f\\x05\\x01\\x05\\x04\\x05\\x10\\x05\\x11\\x06\\x02\\x06\\x07\\x06\\x08\\x06\\x12\\x07\\x06\\x07\\x08\\x07\\x13\\x07\\x14\\x08\\x06\\x08\\x07\\x08\\x15\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x03\\r\\x03\\x0e\\x04\\x0f\\x04\\x10\\x05\\x11\\x05\\x12\\x06\\x13\\x07\\x14\\x07\\x15\\x08\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01\\x16\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01.\\n\"\\n\\x04atom\\x12\\x1a\\x1a\\x18\\n\\x16\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n:\\n\\x04bond\\x122\\x1a0\\n.\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_tfrecord(data['dict'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split our data into a separate training (used to learn parameters of our neural network), validation (used to assess when our model is done training) and test set (used to assess the model's performance after training). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, shuffle=True, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(train_data, train_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data in TFDataset format in \"protobuf\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 20250it [00:06, 3190.10it/s]\n",
      "valid: 2250it [00:00, 3170.36it/s]\n",
      "test: 2500it [00:00, 3236.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, dataset in zip(['train', 'valid', 'test'], [train_data, valid_data, test_data]):\n",
    "    # Open the file in which to store the data\n",
    "    with tf.io.TFRecordWriter(f'datasets/{name}_data.proto') as writer:\n",
    "        # Loop over each entry in the dataset\n",
    "        for _, entry in tqdm(dataset.iterrows(), desc=name):\n",
    "            # Store some output values in the dictionary as well\n",
    "            record = entry['dict']\n",
    "            for o in ['u0_atom', 'bandgap']:\n",
    "                record[o] = entry[o]\n",
    "            writer.write(make_tfrecord(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We are now ready to train an MPNN. Note we have a test set that is 10% of our full dataset (2500 entries) and the training set is 90% of the remaining 90% of the full data (20250 entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
