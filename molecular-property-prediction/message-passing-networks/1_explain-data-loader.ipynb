{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a TF Data Loader\n",
    "This notebook shows how we go from serialized TFRecords, which we saved in the [previous notebook](./0_save-training-data.ipynb) to training batches. TF Data Loaders are created by defining a set of operations that convert a stream of data using [Tensorflow's Data module](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file = 'datasets/train_data.proto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Records from Disk\n",
    "Our records are stored as serialized protobuf records. Origin of the stream of data will be to read from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 20:38:43.007730: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-27 20:38:43.009091: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-27 20:38:43.012065: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this loader produces a dataset of strings, which are the serialized data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 20:38:43.051610: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-27 20:38:43.052954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3693060000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\n\\x89\\x02\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01\\x13\\n4\\n\\x04bond\\x12,\\x1a*\\n(\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nd\\n\\x0cconnectivity\\x12T\\x1aR\\nP\\x00\\x01\\x01\\x00\\x01\\x02\\x01\\t\\x02\\x01\\x02\\x03\\x02\\x04\\x02\\n\\x03\\x02\\x03\\x04\\x03\\x0b\\x03\\x0c\\x04\\x02\\x04\\x03\\x04\\x05\\x04\\x08\\x05\\x04\\x05\\x06\\x05\\r\\x05\\x0e\\x06\\x05\\x06\\x07\\x06\\x0f\\x06\\x10\\x07\\x06\\x07\\x08\\x07\\x11\\x07\\x12\\x08\\x04\\x08\\x07\\t\\x01\\n\\x02\\x0b\\x03\\x0c\\x03\\r\\x05\\x0e\\x05\\x0f\\x06\\x10\\x06\\x11\\x07\\x12\\x07\\n\\x13\\n\\x07bandgap\\x12\\x08\\x12\\x06\\n\\x04RI]>\\n\\x1f\\n\\x04atom\\x12\\x17\\x1a\\x15\\n\\x13\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01(\\n\\x13\\n\\x07u0_atom\\x12\\x08\\x12\\x06\\n\\x04\\xd9%>\\xc0'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance reasons, we are going to form these records into batches first before parsing.\n",
    "\n",
    "- `shuffle` creates a buffer of entries (128 in our case) and randomly picks an entry from that buffer\n",
    "- `batch` pulls multiple entries and returns them as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None,), types: tf.string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b'\\n\\xf3\\x01\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01\"\\nX\\n\\x0cconnectivity\\x12H\\x1aF\\nD\\x00\\x01\\x00\\t\\x01\\x00\\x01\\x02\\x01\\x08\\x02\\x01\\x02\\x03\\x03\\x02\\x03\\x04\\x03\\x07\\x03\\n\\x04\\x03\\x04\\x05\\x04\\x06\\x04\\x0b\\x05\\x04\\x05\\x06\\x05\\x0c\\x06\\x04\\x06\\x05\\x06\\x07\\x06\\r\\x07\\x03\\x07\\x06\\x07\\x08\\x08\\x01\\x08\\x07\\x08\\x0e\\t\\x00\\n\\x03\\x0b\\x04\\x0c\\x05\\r\\x06\\x0e\\x08\\n\\x1b\\n\\x04atom\\x12\\x13\\x1a\\x11\\n\\x0f\\x02\\x01\\x03\\x01\\x01\\x02\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x13\\n\\x07bandgap\\x12\\x08\\x12\\x06\\n\\x04q\\xacK>\\n.\\n\\x04bond\\x12&\\x1a$\\n\"\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x13\\n\\x07u0_atom\\x12\\x08\\x12\\x06\\n\\x04e4\\x1b\\xc0\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01\\x0f',\n",
       "       b'\\n\\xa5\\x02\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01\\x17\\nt\\n\\x0cconnectivity\\x12d\\x1ab\\n`\\x00\\x01\\x00\\t\\x00\\n\\x00\\x0b\\x01\\x00\\x01\\x02\\x01\\x0c\\x01\\r\\x02\\x01\\x02\\x03\\x02\\x08\\x03\\x02\\x03\\x04\\x03\\x0e\\x04\\x03\\x04\\x05\\x04\\x0f\\x04\\x10\\x05\\x04\\x05\\x06\\x05\\x08\\x05\\x11\\x06\\x05\\x06\\x07\\x06\\x08\\x06\\x12\\x07\\x06\\x07\\x13\\x07\\x14\\x07\\x15\\x08\\x02\\x08\\x05\\x08\\x06\\x08\\x16\\t\\x00\\n\\x00\\x0b\\x00\\x0c\\x01\\r\\x01\\x0e\\x03\\x0f\\x04\\x10\\x04\\x11\\x05\\x12\\x06\\x13\\x07\\x14\\x07\\x15\\x07\\x16\\x08\\n\\x13\\n\\x07u0_atom\\x12\\x08\\x12\\x06\\n\\x04\\x18\\xb1b\\xc0\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x010\\n\\x13\\n\\x07bandgap\\x12\\x08\\x12\\x06\\n\\x04Z\\xf5y>\\n#\\n\\x04atom\\x12\\x1b\\x1a\\x19\\n\\x17\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n<\\n\\x04bond\\x124\\x1a2\\n0\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a two member batch of arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to convert the batches of records into a set of tensors.\n",
    "\n",
    "To do so, you must define which elements of the protobuf message you would like to read from the object and define their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_records(example_proto):\n",
    "    \"\"\"Parse data from the TFRecord\"\"\"\n",
    "    features = {\n",
    "        'u0_atom': tf.io.FixedLenFeature([], tf.float32, default_value=np.nan),\n",
    "        'n_atom': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'n_bond': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'connectivity': tf.io.VarLenFeature(tf.int64),\n",
    "        'atom': tf.io.VarLenFeature(tf.int64),\n",
    "        'bond': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    return tf.io.parse_example(example_proto, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this function to the data chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {atom: (None, None), bond: (None, None), connectivity: (None, None), n_atom: (None,), n_bond: (None,), u0_atom: (None,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, n_atom: tf.int64, n_bond: tf.int64, u0_atom: tf.float32}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have Tensor objects in a dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing to Make MPNN-compatible batches\n",
    "Tensorflow now can understand the data types, but these data are not yet in a form we can use in our MPNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f31783c9460>,\n",
       " 'bond': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f31783c94c0>,\n",
       " 'connectivity': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f31783c9ac0>,\n",
       " 'n_atom': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([16, 17])>,\n",
       " 'n_bond': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([32, 32])>,\n",
       " 'u0_atom': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-2.579495, -2.631878], dtype=float32)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our big issue is that the `SparseTensor` objects cannot be used in many Tensorflow operations. We need to convert them to Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_for_batching(dataset):\n",
    "    \"\"\"Make the variable length arrays into RaggedArrays.\n",
    "    \n",
    "    Allows them to be merged together in batches\"\"\"\n",
    "    for c in ['atom', 'bond', 'connectivity']:\n",
    "        expanded = tf.expand_dims(dataset[c].values, axis=0, name=f'expand_{c}')\n",
    "        dataset[c] = tf.RaggedTensor.from_tensor(expanded)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_for_batching at 0x7f3178412430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function prepare_for_batching at 0x7f3178412430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {atom: (1, None), bond: (1, None), connectivity: (1, None), n_atom: (None,), n_bond: (None,), u0_atom: (None,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, n_atom: tf.int64, n_bond: tf.int64, u0_atom: tf.float32}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records).map(prepare_for_batching)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tf.RaggedTensor [[1, 1, 2, 1, 1, 3, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]>,\n",
       " 'bond': <tf.RaggedTensor [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]>,\n",
       " 'connectivity': <tf.RaggedTensor [[0, 1, 0, 9, 0, 10, 0, 11, 1, 0, 1, 2, 1, 6, 1, 12, 2, 1, 2, 3, 2, 4, 3, 2, 3, 13, 3, 14, 3, 15, 4, 2, 4, 5, 4, 6, 5, 4, 6, 1, 6, 4, 6, 7, 6, 8, 7, 6, 7, 16, 7, 17, 7, 18, 8, 6, 8, 19, 9, 0, 10, 0, 11, 0, 12, 1, 13, 3, 14, 3, 15, 3, 16, 7, 17, 7, 18, 7, 19, 8, 0, 1, 0, 9, 0, 10, 0, 11, 1, 0, 1, 2, 1, 5, 2, 1, 2, 3, 2, 4, 2, 7, 3, 2, 3, 12, 3, 13, 3, 14, 4, 2, 4, 5, 4, 15, 4, 16, 5, 1, 5, 4, 5, 6, 5, 7, 6, 5, 6, 17, 6, 18, 6, 19, 7, 2, 7, 5, 7, 8, 7, 20, 8, 7, 8, 21, 9, 0, 10, 0, 11, 0, 12, 3, 13, 3, 14, 3, 15, 4, 16, 4, 17, 6, 18, 6, 19, 6, 20, 7, 21, 8]]>,\n",
       " 'n_atom': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([20, 22])>,\n",
       " 'n_bond': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([40, 46])>,\n",
       " 'u0_atom': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-3.018767, -3.202081], dtype=float32)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data close to the form we need it, minus a few things:\n",
    "\n",
    "- We can't easily know which \"node\" corresponds to which training entry because we have stuck multiple graphs into the same batch\n",
    "- The `connectivity` array is the wrong shape. It is a 1D instead of Nx2 array\n",
    "- The node ids in the connectivity arrays are incorrect. Since we have merged multiple graphs, the node 0 of the second graph is no longer at position 0 in the `atom` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_graphs(batch):\n",
    "    \"\"\"Combine multiple graphs into a single network\"\"\"\n",
    "    \n",
    "    # Convert RaggedTensors into vectors\n",
    "    for c in ['atom', 'bond', 'connectivity']:\n",
    "        expanded = tf.expand_dims(batch[c].values, axis=0, name=f'expand_{c}')\n",
    "        batch[c] = tf.RaggedTensor.from_tensor(expanded).flat_values\n",
    "\n",
    "    # Compute the mappings from bond index to graph index\n",
    "    batch_size = tf.size(batch['n_atom'], name='batch_size')\n",
    "    mol_id = tf.range(batch_size, name='mol_inds')\n",
    "    batch['node_graph_indices'] = tf.repeat(mol_id, batch['n_atom'], axis=0)\n",
    "    batch['bond_graph_indices'] = tf.repeat(mol_id, batch['n_bond'], axis=0)\n",
    "\n",
    "    # Reshape the connectivity matrix to (None, 2)\n",
    "    batch['connectivity'] = tf.reshape(batch['connectivity'], (-1, 2))\n",
    "\n",
    "    # Compute offsets for the connectivity matrix\n",
    "    offset_values = tf.cumsum(batch['n_atom'], exclusive=True)\n",
    "    offsets = tf.repeat(offset_values, batch['n_bond'], name='offsets', axis=0)\n",
    "    batch['connectivity'] += tf.expand_dims(offsets, 1)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function combine_graphs at 0x7f31783b9040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function combine_graphs at 0x7f31783b9040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {atom: (None,), bond: (None,), connectivity: (None, 2), n_atom: (None,), n_bond: (None,), u0_atom: (None,), node_graph_indices: (None,), bond_graph_indices: (None,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, n_atom: tf.int64, n_bond: tf.int64, u0_atom: tf.float32, node_graph_indices: tf.int32, bond_graph_indices: tf.int32}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records).map(prepare_for_batching).map(combine_graphs)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the output, you will notice two new values:\n",
    "- `node_graph_indices`, which stores which molecule (\"graph\") each atom (\"node\") belongs to.\n",
    "- `bond_graph_indices`, which stores which molecule each bond belongs to.\n",
    "\n",
    "This operation converts our vectors into the right shape now. And, because we did all of these operations in Tensorflow, we can delegate these operations to the GPU and use Tensorflow's automated parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       " array([3, 1, 1, 1, 2, 1, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0])>,\n",
       " 'bond': <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>,\n",
       " 'connectivity': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[ 0,  1],\n",
       "        [ 1,  0],\n",
       "        [ 1,  2],\n",
       "        [ 1,  9],\n",
       "        [ 2,  1],\n",
       "        [ 2,  3],\n",
       "        [ 2, 10],\n",
       "        [ 2, 11],\n",
       "        [ 3,  2],\n",
       "        [ 3,  4],\n",
       "        [ 3,  8],\n",
       "        [ 3, 12],\n",
       "        [ 4,  3],\n",
       "        [ 4,  5],\n",
       "        [ 4, 13],\n",
       "        [ 5,  4],\n",
       "        [ 5,  6],\n",
       "        [ 5,  7],\n",
       "        [ 6,  5],\n",
       "        [ 7,  5],\n",
       "        [ 7,  8],\n",
       "        [ 7, 14],\n",
       "        [ 8,  3],\n",
       "        [ 8,  7],\n",
       "        [ 8, 15],\n",
       "        [ 9,  1],\n",
       "        [10,  2],\n",
       "        [11,  2],\n",
       "        [12,  3],\n",
       "        [13,  4],\n",
       "        [14,  7],\n",
       "        [15,  8],\n",
       "        [16, 17],\n",
       "        [17, 16],\n",
       "        [17, 18],\n",
       "        [18, 17],\n",
       "        [18, 19],\n",
       "        [18, 21],\n",
       "        [18, 25],\n",
       "        [19, 18],\n",
       "        [19, 20],\n",
       "        [20, 19],\n",
       "        [21, 18],\n",
       "        [21, 22],\n",
       "        [21, 24],\n",
       "        [22, 21],\n",
       "        [22, 23],\n",
       "        [22, 26],\n",
       "        [22, 27],\n",
       "        [23, 22],\n",
       "        [23, 24],\n",
       "        [23, 28],\n",
       "        [23, 29],\n",
       "        [24, 21],\n",
       "        [24, 23],\n",
       "        [24, 30],\n",
       "        [24, 31],\n",
       "        [25, 18],\n",
       "        [26, 22],\n",
       "        [27, 22],\n",
       "        [28, 23],\n",
       "        [29, 23],\n",
       "        [30, 24],\n",
       "        [31, 24]])>,\n",
       " 'n_atom': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([16, 16])>,\n",
       " 'n_bond': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([32, 32])>,\n",
       " 'u0_atom': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-2.647026, -2.579495], dtype=float32)>,\n",
       " 'node_graph_indices': <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
       " 'bond_graph_indices': <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       dtype=int32)>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
